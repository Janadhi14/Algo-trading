{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf \n",
    "import tensorflow as tf\n",
    "import sklearn \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>7.611786</td>\n",
       "      <td>7.619643</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>7.526071</td>\n",
       "      <td>6.434926</td>\n",
       "      <td>352410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>7.643214</td>\n",
       "      <td>6.535083</td>\n",
       "      <td>493729600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>7.664286</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>7.616071</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>6.546384</td>\n",
       "      <td>601904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>7.656429</td>\n",
       "      <td>7.686786</td>\n",
       "      <td>7.526786</td>\n",
       "      <td>7.534643</td>\n",
       "      <td>6.442255</td>\n",
       "      <td>552160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>7.562500</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466071</td>\n",
       "      <td>7.520714</td>\n",
       "      <td>6.430346</td>\n",
       "      <td>477131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-23</th>\n",
       "      <td>136.820007</td>\n",
       "      <td>138.589996</td>\n",
       "      <td>135.630005</td>\n",
       "      <td>138.270004</td>\n",
       "      <td>138.270004</td>\n",
       "      <td>72433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-24</th>\n",
       "      <td>139.899994</td>\n",
       "      <td>141.910004</td>\n",
       "      <td>139.770004</td>\n",
       "      <td>141.660004</td>\n",
       "      <td>141.660004</td>\n",
       "      <td>89116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>142.699997</td>\n",
       "      <td>143.490005</td>\n",
       "      <td>140.970001</td>\n",
       "      <td>141.660004</td>\n",
       "      <td>141.660004</td>\n",
       "      <td>70207900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>142.130005</td>\n",
       "      <td>143.419998</td>\n",
       "      <td>137.320007</td>\n",
       "      <td>137.440002</td>\n",
       "      <td>137.440002</td>\n",
       "      <td>67083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>137.460007</td>\n",
       "      <td>140.669998</td>\n",
       "      <td>136.669998</td>\n",
       "      <td>139.229996</td>\n",
       "      <td>139.229996</td>\n",
       "      <td>66242400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3145 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2009-12-31    7.611786    7.619643    7.520000    7.526071    6.434926   \n",
       "2010-01-04    7.622500    7.660714    7.585000    7.643214    6.535083   \n",
       "2010-01-05    7.664286    7.699643    7.616071    7.656429    6.546384   \n",
       "2010-01-06    7.656429    7.686786    7.526786    7.534643    6.442255   \n",
       "2010-01-07    7.562500    7.571429    7.466071    7.520714    6.430346   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2022-06-23  136.820007  138.589996  135.630005  138.270004  138.270004   \n",
       "2022-06-24  139.899994  141.910004  139.770004  141.660004  141.660004   \n",
       "2022-06-27  142.699997  143.490005  140.970001  141.660004  141.660004   \n",
       "2022-06-28  142.130005  143.419998  137.320007  137.440002  137.440002   \n",
       "2022-06-29  137.460007  140.669998  136.669998  139.229996  139.229996   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2009-12-31  352410800  \n",
       "2010-01-04  493729600  \n",
       "2010-01-05  601904800  \n",
       "2010-01-06  552160000  \n",
       "2010-01-07  477131200  \n",
       "...               ...  \n",
       "2022-06-23   72433800  \n",
       "2022-06-24   89116800  \n",
       "2022-06-27   70207900  \n",
       "2022-06-28   67083400  \n",
       "2022-06-29   66242400  \n",
       "\n",
       "[3145 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple = yf.download(\"AAPL\", start = \"2010-01-01\", end =\"2022-07-01\" )\n",
    "# creating a variable called apple and then downloading using yahoo finiance \n",
    "Apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising the data \n",
    "- the data needs to be organised so we are able to process it using tensorflow \n",
    "- we need take in the 4 columns and then create a tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we need to use sklearn o transform the data \n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# now lets create a column transformaer to transform the column \n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"Open\", \"High\", \"Low\", \"Close\"]), \n",
    "    (OneHotEncoder(handle_unknown = \"ignore\"), [\"Adj Close\", \"Volume\"]) # here it is going to one hit encode the values \n",
    "    ) # takes in StandardScalar or MinMaxScalar and OneHotEncoder \n",
    "# we want to tunr all the values in these columns into vlause betwen 0 and on ebecasue they are numerical vlaes, they are not objects of\n",
    "X = variables.drop(\"Adj Close\" , axis = 1)\n",
    "y = variables[\"charges\"]\n",
    "# now we want to the model to learn the data and need to split data \n",
    "X_train,X_test, y_train, y_test =train_test_split(X,y, test_size = 0.2, random_state = 42)\n",
    "# fitting the column transformer to our training data \n",
    "ct.fit(X_train) \n",
    "# transform training and test data with automatic with normalization from the training data \n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Strat:\n",
    "we want to create a parameter where we are able to see a large change(price swing) use the condiitons before and analyse the data for patterns whcih may give rise to a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation = \"relu\"), \n",
    "    tf.keras.layers.Dense(1)\n",
    "   \n",
    "])\n",
    "model_4.compile(loss = \"binary_crossentropy\", # dependent on the problem type \n",
    "                optimizer = tf.keras.optimizers.Adam(lr = 0.001),\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "with tf.device('/cpu:0'): history = model_4.fit(X, y, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1ed3d0d51d0d9fc84e9feca67a2c96385eab8afcf16092b40709d9c6021dc22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
